[
  {
    "objectID": "02_Model.html",
    "href": "02_Model.html",
    "title": "Define column names for different models",
    "section": "",
    "text": "# import required libraries\nimport pandas as pd\n# read the data\ndata_df = pd.read_csv('250807_FinalCleanedData_PT.csv')\ndata_df['di_code'] = data_df['di_code'].astype(int)\n\n# filter the data\nprint(data_df.keys())\ndata_df.head()\n\nIndex(['Unnamed: 0.1', 'caseid', 'weight', 'wave', 'state', 'district',\n       'urban', 'gender', 'age', 'caste',\n       ...\n       'A63_p2', 'A63_p90', 'A63_p95', 'A63_p98', 'A63_sum', 'A63_mean',\n       'A63_min', 'A63_max', 'A63_count', 'split'],\n      dtype='object', length=608)\n\n\n\n\n\n\n\n\n\nUnnamed: 0.1\ncaseid\nweight\nwave\nstate\ndistrict\nurban\ngender\nage\ncaste\n...\nA63_p2\nA63_p90\nA63_p95\nA63_p98\nA63_sum\nA63_mean\nA63_min\nA63_max\nA63_count\nsplit\n\n\n\n\n0\n0\n10001\n0.840547\n2024\nNE\nEast Khasi Hills\nUrban\nMale\n18-29\nScheduled Castes/Tribes\n...\n-0.124567\n0.103406\n0.124567\n0.147697\n43582.604336\n0.012406\n-0.267958\n0.327812\n3519450\ntrain\n\n\n1\n1\n10002\n1.360886\n2024\nUT\nLeh\nRural\nFemale\n45+\nScheduled Castes/Tribes\n...\n-0.206936\n0.093564\n0.141730\n0.267958\n-117536.992772\n-0.024344\n-0.318893\n0.346021\n4837249\ntrain\n\n\n2\n2\n10002\n1.360886\n2024\nUT\nLeh\nRural\nFemale\n45+\nScheduled Castes/Tribes\n...\n-0.221453\n0.103406\n0.130165\n0.160000\n-248714.921995\n-0.038288\n-0.327812\n0.318893\n6508506\ntrain\n\n\n3\n3\n10003\n0.640417\n2024\nUT\nDaman & Diu\nRural\nMale\n30-44\nOther Castes\n...\n0.032541\n0.221453\n0.236463\n0.244152\n10633.937208\n0.124858\n-0.051734\n0.355309\n86148\ntrain\n\n\n4\n4\n10003\n0.640417\n2024\nUT\nDaman & Diu\nRural\nMale\n30-44\nOther Castes\n...\n-0.022207\n0.206936\n0.244152\n0.259900\n4060.501217\n0.087937\n-0.113741\n0.355309\n47012\ntrain\n\n\n\n\n5 rows × 608 columns\n# create keys for all four models\nfeatures_list_model1 = ['age', 'gender', 'urban', 'caste', 'di_code']\nfeatures_list_model2 = features_list_model1 + ['mean_monthly_avg_rd_MD', 'precip_sum_mm', 'precip_mean_mm', 'mean_tmax', 'district_flood_sentiment', 'state_flood_sentiment']\nfeatures_list_model3 = features_list_model1 + [\n    f'{var}_{metric}'\n    for var in sorted(set([\n        data.split('_')[0] \n        for data in data_df.loc[:, data_df.columns.str.startswith('A')].keys()\n    ]))\n    for metric in ['min', 'p2', 'mean', 'p98', 'max', 'sum', 'count']\n]\nfeatures_list_model4 = list(set(features_list_model2 + features_list_model3))\n\nflood_y_key = 'n7fy23_recode'\ndrought_y_key = 'n7dy23_recode'",
    "crumbs": [
      "Model",
      "Define column names for different models"
    ]
  },
  {
    "objectID": "02_Model.html#prepare-data-for-the-model",
    "href": "02_Model.html#prepare-data-for-the-model",
    "title": "Define column names for different models",
    "section": "Prepare data for the model",
    "text": "Prepare data for the model\n\n%%time\n\n%%time\nfrom sklearn.preprocessing import LabelEncoder\n\n# Encode categorical variables FIRST (on full dataset)\ndata_encoded = data_df.copy()\nencoders = {}\n\nfor var in ['age', 'gender', 'urban', 'caste', 'di_code']:\n    encoders[var] = LabelEncoder()\n    data_encoded[var] = encoders[var].fit_transform(data_df[var])\n\n# Split the encoded data (general variables)\nX_train_encoded = data_encoded[data_encoded['split'] == 'train']\nX_test_encoded = data_encoded[data_encoded['split'] == 'test']\ny_train = data_encoded[data_encoded['split'] == 'train'][flood_y_key]\ny_test = data_encoded[data_encoded['split'] == 'test'][flood_y_key]\n\nprint(f\"X_train_encoded shape: {X_train_encoded.shape}\")\nprint(f\"y_train shape: {y_train.shape}\")\nprint(f\"X_test_encoded shape: {X_test_encoded.shape}\")\nprint(f\"y_test shape: {y_test.shape}\")\n\nX_train_encoded shape: (9376, 608)\ny_train shape: (9376,)\nX_test_encoded shape: (2047, 608)\ny_test shape: (2047,)\nCPU times: user 40.3 ms, sys: 39 ms, total: 79.2 ms\nWall time: 76.9 ms\nCPU times: user 41.2 ms, sys: 39.1 ms, total: 80.3 ms\nWall time: 78 ms\n\n\n\nimport time\nimport os\nimport joblib\nimport pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n\ndef train_models_with_features(X_train_encoded, X_test_encoded, y_train, y_test, \n                               features_list, model_name_suffix=\"\"):\n    \"\"\"\n    Train multiple models with specified features and save results\n    \n    Parameters:\n    -----------\n    X_train_encoded : DataFrame\n        Training features (encoded)\n    X_test_encoded : DataFrame  \n        Test features (encoded)\n    y_train : array-like\n        Training target\n    y_test : array-like\n        Test target\n    features_list : list\n        List of feature names to use\n    model_name_suffix : str\n        Suffix to add to saved model files (e.g., \"model1\", \"model2\")\n    \n    Returns:\n    --------\n    tuple: (metrics_df, trained_models, feature_importance_results)\n    \"\"\"\n    \n    print(f\"{'='*60}\")\n    print(f\"Training models with {len(features_list)} features\")\n    if model_name_suffix:\n        print(f\"Model suffix: {model_name_suffix}\")\n    print(f\"{'='*60}\")\n    \n    # Extract features\n    X_train_subset = X_train_encoded[features_list]\n    X_test_subset = X_test_encoded[features_list]\n    \n    # Define models and parameters\n    models = {\n        'RandomForest': (RandomForestClassifier(random_state=42), {\n            'n_estimators': [10, 50, 100, 200], 'max_depth': [10, 20, None]}),\n        \n        'GradientBoosting': (GradientBoostingClassifier(random_state=42), {\n            'n_estimators': [100, 200], 'learning_rate': [0.1, 0.2], 'max_depth': [3, 5]}),\n        \n        'LogisticRegression': (LogisticRegression(random_state=42, max_iter=1000), {\n            'C': [0.1, 1, 10], 'penalty': ['l1', 'l2'], 'solver': ['liblinear']})\n    }\n    \n    results = []\n    trained_models = {}\n    feature_importance_results = {}\n    \n    # Train each model\n    for name, (model, params) in models.items():\n        print(f\"Training {name}...\")\n        start = time.time()\n        \n        grid = GridSearchCV(model, params, cv=5, scoring='accuracy')\n        grid.fit(X_train_subset, y_train)\n        \n        # Store the best estimator\n        trained_models[name] = grid.best_estimator_\n        \n        # Make predictions\n        train_pred = grid.predict(X_train_subset)\n        test_pred = grid.predict(X_test_subset)\n        train_proba = grid.predict_proba(X_train_subset)[:, 1]\n        test_proba = grid.predict_proba(X_test_subset)[:, 1]\n        \n        # Calculate metrics\n        results.append({\n            'Model': name,\n            'Train_Accuracy': accuracy_score(y_train, train_pred),\n            'Test_Accuracy': accuracy_score(y_test, test_pred),\n            'Train_Precision': precision_score(y_train, train_pred),\n            'Test_Precision': precision_score(y_test, test_pred),\n            'Train_Recall': recall_score(y_train, train_pred),\n            'Test_Recall': recall_score(y_test, test_pred),\n            'Train_F1': f1_score(y_train, train_pred),\n            'Test_F1': f1_score(y_test, test_pred),\n            'Train_AUC': roc_auc_score(y_train, train_proba),\n            'Test_AUC': roc_auc_score(y_test, test_proba)\n        })\n        \n        print(f\"{name} - Test Acc: {results[-1]['Test_Accuracy']:.3f}, Test AUC: {results[-1]['Test_AUC']:.3f}\")\n        print(f\"Time: {time.time()-start:.1f}s\\n\")\n    \n    # Create metrics DataFrame\n    metrics_df = pd.DataFrame(results)\n    \n    # Print results nicely\n    print(\"FINAL RESULTS:\")\n    display_df = metrics_df.round(3).set_index('Model').T\n    print(display_df)\n    print()\n    \n    # Extract feature importance\n    print(\"Extracting feature importance...\")\n    for model_name, trained_model in trained_models.items():\n        importance_df = get_feature_importance(trained_model, model_name, features_list)\n        if importance_df is not None:\n            feature_importance_results[model_name] = importance_df\n            print(f\"{model_name} - Top 5 features:\")\n            print(importance_df.head(5)[['Feature', 'Importance']].to_string(index=False))\n            print()\n    \n    # Save everything\n    save_results(metrics_df, trained_models, feature_importance_results, \n                 features_list, model_name_suffix)\n    \n    return metrics_df, trained_models, feature_importance_results\n\ndef get_feature_importance(model, model_name, feature_names):\n    \"\"\"Extract feature importance based on model type\"\"\"\n    \n    if hasattr(model, 'feature_importances_'):\n        # Tree-based models\n        importance = model.feature_importances_\n        importance_type = 'Gini/Entropy Importance'\n        \n    elif hasattr(model, 'coef_'):\n        # Linear models\n        importance = np.abs(model.coef_[0])\n        importance_type = 'Coefficient Magnitude'\n        \n    else:\n        print(f\"Feature importance not available for {model_name}\")\n        return None\n    \n    # Create feature importance DataFrame\n    feature_importance_df = pd.DataFrame({\n        'Feature': feature_names,\n        'Importance': importance,\n        'Model': model_name,\n        'Importance_Type': importance_type\n    }).sort_values('Importance', ascending=False)\n    \n    return feature_importance_df\n\ndef save_results(metrics_df, trained_models, feature_importance_results, \n                 features_list, model_name_suffix):\n    \"\"\"Save all results to files\"\"\"\n    \n    # Create directory\n    save_dir = 'saved_models'\n    os.makedirs(save_dir, exist_ok=True)\n    \n    # Create file suffix\n    suffix = f\"_{model_name_suffix}\" if model_name_suffix else \"\"\n    \n    # Save models\n    for model_name, trained_model in trained_models.items():\n        joblib.dump(trained_model, f'{save_dir}/{model_name}_model{suffix}.pkl')\n    \n    # Save feature importance\n    for model_name, importance_df in feature_importance_results.items():\n        importance_df.to_csv(f'{save_dir}/{model_name}_feature_importance{suffix}.csv', index=False)\n    \n    # Save metrics and features\n    metrics_df.to_csv(f'{save_dir}/model_metrics{suffix}.csv', index=False)\n    joblib.dump(features_list, f'{save_dir}/feature_list{suffix}.pkl')\n    \n    print(f\"Results saved with suffix '{suffix}' in '{save_dir}/' directory\")\n\n\n\n\n%%time\n\n# Train with first set of features\nmetrics1, models1, importance1 = train_models_with_features(\n    X_train_encoded[features_list_model1], X_test_encoded[features_list_model1], y_train, y_test, \n    features_list_model1, \"model1\"\n)\n\n# Train with second set of features  \nmetrics2, models2, importance2 = train_models_with_features(\n    X_train_encoded[features_list_model2], X_test_encoded[features_list_model2], y_train, y_test,\n    features_list_model2, \"model2\"\n)\n\n# Train with third set of features\nmetrics3, models3, importance3 = train_models_with_features(\n    X_train_encoded[features_list_model3], X_test_encoded[features_list_model3], y_train, y_test,\n    features_list_model3, \"model3\"\n)\n\n# Train with fourth set of features\nmetrics4, models4, importance4 = train_models_with_features(\n    X_train_encoded[features_list_model4], X_test_encoded[features_list_model4], y_train, y_test,\n    features_list_model4, \"model4\"\n)\n\n============================================================\nTraining models with 5 features\nModel suffix: model1\n============================================================\nTraining RandomForest...\nRandomForest - Test Acc: 0.558, Test AUC: 0.572\nTime: 26.2s\n\nTraining GradientBoosting...\nGradientBoosting - Test Acc: 0.555, Test AUC: 0.585\nTime: 24.2s\n\nTraining LogisticRegression...\nLogisticRegression - Test Acc: 0.581, Test AUC: 0.612\nTime: 0.3s\n\nFINAL RESULTS:\nModel            RandomForest  GradientBoosting  LogisticRegression\nTrain_Accuracy          0.711             0.627               0.561\nTest_Accuracy           0.558             0.555               0.581\nTrain_Precision         0.692             0.609               0.546\nTest_Precision          0.551             0.559               0.593\nTrain_Recall            0.704             0.602               0.437\nTest_Recall             0.557             0.468               0.479\nTrain_F1                0.698             0.605               0.485\nTest_F1                 0.554             0.509               0.530\nTrain_AUC               0.793             0.681               0.570\nTest_AUC                0.572             0.585               0.612\n\nExtracting feature importance...\nRandomForest - Top 5 features:\nFeature  Importance\ndi_code    0.876304\n    age    0.051676\n  urban    0.025170\n gender    0.024492\n  caste    0.022359\n\nGradientBoosting - Top 5 features:\nFeature  Importance\ndi_code    0.869581\n gender    0.040041\n  urban    0.035893\n  caste    0.029276\n    age    0.025209\n\nLogisticRegression - Top 5 features:\nFeature  Importance\n  urban    0.223965\n gender    0.140166\n  caste    0.022219\n    age    0.001772\ndi_code    0.001372\n\nResults saved with suffix '_model1' in 'saved_models/' directory\n============================================================\nTraining models with 11 features\nModel suffix: model2\n============================================================\nTraining RandomForest...\nRandomForest - Test Acc: 0.559, Test AUC: 0.599\nTime: 35.9s\n\nTraining GradientBoosting...\nGradientBoosting - Test Acc: 0.572, Test AUC: 0.608\nTime: 51.0s\n\nTraining LogisticRegression...\nLogisticRegression - Test Acc: 0.583, Test AUC: 0.616\nTime: 1.5s\n\nFINAL RESULTS:\nModel            RandomForest  GradientBoosting  LogisticRegression\nTrain_Accuracy          0.713             0.642               0.561\nTest_Accuracy           0.559             0.572               0.583\nTrain_Precision         0.699             0.626               0.545\nTest_Precision          0.555             0.578               0.581\nTrain_Recall            0.694             0.611               0.450\nTest_Recall             0.536             0.485               0.555\nTrain_F1                0.696             0.618               0.493\nTest_F1                 0.545             0.527               0.568\nTrain_AUC               0.790             0.699               0.574\nTest_AUC                0.599             0.608               0.616\n\nExtracting feature importance...\nRandomForest - Top 5 features:\n               Feature  Importance\n               di_code    0.199970\n             mean_tmax    0.110452\n                   age    0.101366\n        precip_mean_mm    0.099343\nmean_monthly_avg_rd_MD    0.097874\n\nGradientBoosting - Top 5 features:\n               Feature  Importance\n               di_code    0.425632\n        precip_mean_mm    0.114192\nmean_monthly_avg_rd_MD    0.091233\n         precip_sum_mm    0.072853\n             mean_tmax    0.066257\n\nLogisticRegression - Top 5 features:\n                 Feature  Importance\ndistrict_flood_sentiment    0.288520\n                   urban    0.203483\n                  gender    0.130968\n   state_flood_sentiment    0.067221\n                   caste    0.018214\n\nResults saved with suffix '_model2' in 'saved_models/' directory\n============================================================\nTraining models with 453 features\nModel suffix: model3\n============================================================\nTraining RandomForest...\nRandomForest - Test Acc: 0.578, Test AUC: 0.613\nTime: 202.6s\n\nTraining GradientBoosting...\nGradientBoosting - Test Acc: 0.574, Test AUC: 0.610\nTime: 1749.2s\n\nTraining LogisticRegression...\nLogisticRegression - Test Acc: 0.568, Test AUC: 0.603\nTime: 672.2s\n\nFINAL RESULTS:\nModel            RandomForest  GradientBoosting  LogisticRegression\nTrain_Accuracy          0.674             0.649               0.615\nTest_Accuracy           0.578             0.574               0.568\nTrain_Precision         0.672             0.639               0.602\nTest_Precision          0.562             0.564               0.569\nTrain_Recall            0.610             0.596               0.556\nTest_Recall             0.654             0.602               0.506\nTrain_F1                0.640             0.617               0.578\nTest_F1                 0.604             0.582               0.536\nTrain_AUC               0.746             0.708               0.666\nTest_AUC                0.613             0.610               0.603\n\nExtracting feature importance...\nRandomForest - Top 5 features:\nFeature  Importance\n    age    0.098330\n gender    0.060523\n  urban    0.058472\n  caste    0.046900\ndi_code    0.011682\n\nGradientBoosting - Top 5 features:\nFeature  Importance\ndi_code    0.127954\nA13_p98    0.048186\n  urban    0.035895\n gender    0.033993\n    age    0.031684\n\nLogisticRegression - Top 5 features:\n Feature  Importance\nA47_mean    9.589156\nA31_mean    9.521021\n  A04_p2    9.198595\nA39_mean    8.519797\n A55_p98    8.373364\n\nResults saved with suffix '_model3' in 'saved_models/' directory\n============================================================\nTraining models with 459 features\nModel suffix: model4\n============================================================\nTraining RandomForest...\nRandomForest - Test Acc: 0.583, Test AUC: 0.607\nTime: 206.3s\n\nTraining GradientBoosting...\nGradientBoosting - Test Acc: 0.581, Test AUC: 0.610\nTime: 1761.3s\n\nTraining LogisticRegression...\nLogisticRegression - Test Acc: 0.565, Test AUC: 0.602\nTime: 755.5s\n\nFINAL RESULTS:\nModel            RandomForest  GradientBoosting  LogisticRegression\nTrain_Accuracy          0.669             0.639               0.618\nTest_Accuracy           0.583             0.581               0.565\nTrain_Precision         0.666             0.629               0.604\nTest_Precision          0.565             0.570               0.570\nTrain_Recall            0.604             0.585               0.565\nTest_Recall             0.671             0.613               0.480\nTrain_F1                0.634             0.606               0.584\nTest_F1                 0.614             0.591               0.521\nTrain_AUC               0.743             0.694               0.667\nTest_AUC                0.607             0.610               0.602\n\nExtracting feature importance...\nRandomForest - Top 5 features:\nFeature  Importance\n    age    0.103143\n gender    0.062932\n  urban    0.060128\n  caste    0.046354\n A55_p2    0.015196\n\nGradientBoosting - Top 5 features:\nFeature  Importance\ndi_code    0.165189\nA13_p98    0.054686\n gender    0.030675\n A42_p2    0.027677\nA00_max    0.027450\n\nLogisticRegression - Top 5 features:\n Feature  Importance\nA47_mean   13.649137\n A04_p98   10.087420\n A19_min    8.605777\n  A45_p2    8.576165\nA38_mean    8.214301\n\nResults saved with suffix '_model4' in 'saved_models/' directory\nCPU times: user 1h 32min 17s, sys: 5min 51s, total: 1h 38min 9s\nWall time: 1h 31min 26s",
    "crumbs": [
      "Model",
      "Define column names for different models"
    ]
  },
  {
    "objectID": "01_Data.html",
    "href": "01_Data.html",
    "title": "Spatial splitting for ML model",
    "section": "",
    "text": "# import required libraries\nimport sklearn\nimport geopandas as gpd\nimport pandas as pd\n\n\n%%time\n\n# read the data\nmain_df = pd.read_csv('full_extract_ntl_temp_sentiment.csv')\nembeddings_df = pd.read_csv('merged_embstats_full_extract_main.csv')\n\n# remove duplicates\nsize = main_df.shape[0]\nmain_df = main_df.drop_duplicates(subset=['caseid'], keep='first')\nprint(f'{size-main_df.shape[0]} duplicates found in main_df. Removed!')\n\n# join embeddings with the main data\nmain_df = main_df.merge(embeddings_df, on='caseid', how='left')\nprint(f'Size of dataframe after merging embeddings: {result_df.shape[0]}')\n\nmain_df.head()\n\n2034 duplicates found in main_df. Removed!\nSize of dataframe after merging embeddings: 11423\nCPU times: user 1.18 s, sys: 280 ms, total: 1.46 s\nWall time: 1.47 s\n\n\n\n\n\n\n\n\n\ncaseid\nweight_x\nwave_x\nstate_x\ndistrict_x\nurban_x\ngender_x\nage_x\ncaste_x\nn7dy23_recode_x\n...\nA62_count\nA63_p2\nA63_p90\nA63_p95\nA63_p98\nA63_sum\nA63_mean\nA63_min\nA63_max\nA63_count\n\n\n\n\n0\n10001\n0.840547\n2024\nNE\nEast Khasi Hills\nUrban\nMale\n18-29\nScheduled Castes/Tribes\n1\n...\n3519450\n-0.124567\n0.103406\n0.124567\n0.147697\n43582.604336\n0.012406\n-0.267958\n0.327812\n3519450\n\n\n1\n10002\n1.360886\n2024\nUT\nLeh\nRural\nFemale\n45+\nScheduled Castes/Tribes\n1\n...\n4837249\n-0.206936\n0.093564\n0.141730\n0.267958\n-117536.992772\n-0.024344\n-0.318893\n0.346021\n4837249\n\n\n2\n10002\n1.360886\n2024\nUT\nLeh\nRural\nFemale\n45+\nScheduled Castes/Tribes\n1\n...\n6508506\n-0.221453\n0.103406\n0.130165\n0.160000\n-248714.921995\n-0.038288\n-0.327812\n0.318893\n6508506\n\n\n3\n10003\n0.640417\n2024\nUT\nDaman & Diu\nRural\nMale\n30-44\nOther Castes\n1\n...\n86148\n0.032541\n0.221453\n0.236463\n0.244152\n10633.937208\n0.124858\n-0.051734\n0.355309\n86148\n\n\n4\n10003\n0.640417\n2024\nUT\nDaman & Diu\nRural\nMale\n30-44\nOther Castes\n1\n...\n47012\n-0.022207\n0.206936\n0.244152\n0.259900\n4060.501217\n0.087937\n-0.113741\n0.355309\n47012\n\n\n\n\n5 rows × 617 columns\n\n\n\n\n%%time\n\nimport geopandas as gpd\n\n# read the districts shapefile\ndist_gdf = gpd.read_file('India_District_2023_3857.gpkg')\ndist_gdf.boundary.plot()\n\nCPU times: user 2.08 s, sys: 200 ms, total: 2.28 s\nWall time: 2.12 s\n\n\n\n\n\n\n\n\n\n\n%%time\n\nimport geopandas as gpd\nimport numpy as np\nfrom shapely.geometry import Polygon\nimport pandas as pd\n\n# Fast fishnet creation\ndef create_fishnet(gdf, cell_size):\n    minx, miny, maxx, maxy = gdf.total_bounds\n    x_coords = np.arange(minx, maxx + cell_size, cell_size)\n    y_coords = np.arange(miny, maxy + cell_size, cell_size)\n    xx, yy = np.meshgrid(x_coords[:-1], y_coords[:-1])\n    \n    grid_cells = [Polygon([(x, y), (x + cell_size, y), (x + cell_size, y + cell_size), (x, y + cell_size)])\n                  for x, y in zip(xx.flatten(), yy.flatten())]\n    \n    return gpd.GeoDataFrame({'grid_id': range(len(grid_cells)), 'geometry': grid_cells}, crs=gdf.crs)\n\n# No-adjacent test split\ndef no_adjacent_split(gdf, test_size=0.2, random_state=42):\n    np.random.seed(random_state)\n    gdf = gdf.reset_index(drop=True)\n    n_test = int(len(gdf) * test_size)\n    \n    # Build adjacency using spatial index (faster)\n    sindex = gdf.sindex\n    adjacency = {}\n    for idx, geom in enumerate(gdf.geometry):\n        possible_matches = list(sindex.intersection(geom.bounds))\n        neighbors = [i for i in possible_matches if i != idx and gdf.geometry.iloc[i].touches(geom)]\n        adjacency[idx] = neighbors\n    \n    # Greedy selection\n    available = set(range(len(gdf)))\n    test_indices = []\n    \n    while len(test_indices) &lt; n_test and available:\n        candidate = np.random.choice(list(available))\n        test_indices.append(candidate)\n        # Remove candidate and neighbors\n        to_remove = {candidate} | set(adjacency.get(candidate, []))\n        available -= to_remove\n    \n    train_indices = [i for i in range(len(gdf)) if i not in test_indices]\n    return gdf.loc[train_indices], gdf.loc[test_indices]\n\n# Fixed district assignment\ndef assign_districts(districts, train_grid, test_grid):\n    districts = districts.reset_index(drop=True).copy()\n    districts['orig_idx'] = districts.index\n    districts['train_area'] = 0.0\n    districts['test_area'] = 0.0\n    \n    # Calculate overlaps with proper index handling\n    for split_type, grid in [('train', train_grid), ('test', test_grid)]:\n        overlay = gpd.overlay(districts, grid, how='intersection')\n        if not overlay.empty:\n            # Group by original district index and sum areas\n            area_sums = overlay.groupby('orig_idx')['geometry'].apply(lambda x: x.area.sum())\n            # Map back to districts using orig_idx\n            for orig_idx, area in area_sums.items():\n                districts.loc[districts['orig_idx'] == orig_idx, f'{split_type}_area'] = area\n    \n    districts['split'] = (districts['train_area'] &gt;= districts['test_area']).map({True: 'train', False: 'test'})\n    return districts.drop('orig_idx', axis=1)\n\n# Main execution\ncell_size = 250000\nprint(\"Creating fishnet...\")\nfishnet = create_fishnet(dist_gdf, cell_size)\nfishnet_filtered = fishnet[fishnet.intersects(dist_gdf.unary_union)]\n\nprint(\"Splitting with no-adjacent constraint...\")\ntrain_grid, test_grid = no_adjacent_split(fishnet_filtered, test_size=0.2, random_state=55)\n\nprint(\"Assigning districts...\")\ndist_with_splits = assign_districts(dist_gdf, train_grid, test_grid)\n\ntrain_districts = dist_with_splits[dist_with_splits['split'] == 'train']\ntest_districts = dist_with_splits[dist_with_splits['split'] == 'test']\n\nprint(f\"Results: {len(train_grid)} train grid, {len(test_grid)} test grid\")\nprint(f\"Districts: {len(train_districts)} train, {len(test_districts)} test\")\n\nCreating fishnet...\nSplitting with no-adjacent constraint...\nAssigning districts...\nResults: 89 train grid, 22 test grid\nDistricts: 617 train, 116 test\nCPU times: user 59.9 s, sys: 217 ms, total: 1min\nWall time: 1min\n\n\n\n%%time\nimport matplotlib.patches as mpatches\n\n# Set up the figure with publication quality settings\nplt.style.use('default')\nfig, axes = plt.subplots(1, 3, figsize=(20, 8))\n\n# Define colors\ndistrict_color = '#f0f0f0'\ndistrict_edge = '#666666'\ntrain_color = '#2E86AB'  # Professional blue\ntest_color = '#A23B72'   # Professional red/purple\ngrid_color = '#333333'   # Dark gray for grid lines\n\n# Plot 1: Original districts\ndist_gdf.plot(ax=axes[0], \n             color=district_color, \n             edgecolor=district_edge, \n             linewidth=0.3, \n             alpha=0.8)\naxes[0].set_title('(a) District boundaries', fontsize=16, fontweight='bold', pad=20)\naxes[0].set_xlabel('Longitude', fontsize=12)\naxes[0].set_ylabel('Latitude', fontsize=12)\naxes[0].tick_params(labelsize=10)\naxes[0].grid(True, alpha=0.3)\n\n# Plot 2: Districts with fishnet overlay\ndist_gdf.plot(ax=axes[1], \n             color=district_color, \n             edgecolor=district_edge, \n             linewidth=0.3, \n             alpha=0.6)\ntrain_grid.plot(ax=axes[1], \n               facecolor=train_color, \n               edgecolor=grid_color, \n               linewidth=0.8, \n               alpha=0.7)\ntest_grid.plot(ax=axes[1], \n              facecolor=test_color, \n              edgecolor=grid_color, \n              linewidth=0.8, \n              alpha=0.7)\n\n# Create manual legend for plot 2\ntrain_patch = mpatches.Patch(color=train_color, alpha=0.7, label='Training Grid')\ntest_patch = mpatches.Patch(color=test_color, alpha=0.7, label='Testing Grid')\naxes[1].legend(handles=[train_patch, test_patch], fontsize=12, loc='upper right', \n               frameon=True, fancybox=True, shadow=True)\n\naxes[1].set_title('(b) Fishnet Grid Overlay', fontsize=16, fontweight='bold', pad=20)\naxes[1].set_xlabel('Longitude', fontsize=12)\naxes[1].set_ylabel('Latitude', fontsize=12)\naxes[1].tick_params(labelsize=10)\naxes[1].grid(True, alpha=0.3)\n\n# Plot 3: Districts colored by train/test assignment\ntrain_districts.plot(ax=axes[2], \n                    color=train_color, \n                    edgecolor='white', \n                    linewidth=0.5, \n                    alpha=0.8)\ntest_districts.plot(ax=axes[2], \n                   color=test_color, \n                   edgecolor='white', \n                   linewidth=0.5, \n                   alpha=0.8)\n\n# Create manual legend for plot 3\ntrain_district_patch = mpatches.Patch(color=train_color, alpha=0.8, \n                                     label=f'Training Districts (n={len(train_districts)})')\ntest_district_patch = mpatches.Patch(color=test_color, alpha=0.8, \n                                    label=f'Testing Districts (n={len(test_districts)})')\naxes[2].legend(handles=[train_district_patch, test_district_patch], fontsize=12, \n               loc='upper right', frameon=True, fancybox=True, shadow=True)\n\naxes[2].set_title('(c) District Train-Test Assignment', fontsize=16, fontweight='bold', pad=20)\naxes[2].set_xlabel('Longitude', fontsize=12)\naxes[2].set_ylabel('Latitude', fontsize=12)\naxes[2].tick_params(labelsize=10)\naxes[2].grid(True, alpha=0.3)\n\n# Set equal aspect ratio for all subplots\nfor ax in axes:\n    ax.set_aspect('equal')\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['bottom'].set_color('#CCCCCC')\n    ax.spines['left'].set_color('#CCCCCC')\n\n# Adjust layout\nplt.tight_layout()\nplt.subplots_adjust(top=0.9)\nplt.show()\n\n# Save high-quality figure\nfig.savefig('spatial_train_test_split.png', dpi=300, bbox_inches='tight', \n             facecolor='white', edgecolor='none')\n\n\n\n\n\n\n\n\nCPU times: user 23.6 s, sys: 652 ms, total: 24.2 s\nWall time: 23.7 s\n\n\n\ndist_with_splits\n\n\n\n\n\n\n\n\nstate23\nst_code\ndist23\ndi_code\nst_di23\nShape_Leng\nShape_Area\nGeoName\nGEOID\ngeometry\ntrain_area\ntest_area\nsplit\n\n\n\n\n0\nGUJARAT\n24\nMORBI\n673\nGUJARAT, MORBI\n539476.764723\n4.791280e+09\nGUJARAT, MORBI\nx24673\nMULTIPOLYGON (((7916729.974 2657739.258, 79167...\n5.892261e+09\n0.000000e+00\ntrain\n\n\n1\nGUJARAT\n24\nAHMADABAD\n438\nGUJARAT, AHMADABAD\n857254.094647\n6.966374e+09\nGUJARAT, AHMADABAD\nx24438\nMULTIPOLYGON (((8011013.674 2638096.527, 80107...\n8.188204e+09\n3.688279e+08\ntrain\n\n\n2\nGUJARAT\n24\nANAND\n440\nGUJARAT, ANAND\n393046.690523\n3.054307e+09\nGUJARAT, ANAND\nx24440\nMULTIPOLYGON (((8129232.514 2599976.400, 81293...\n1.429556e+09\n2.303346e+09\ntest\n\n\n3\nGUJARAT\n24\nDEVBHUMI DWARKA\n674\nGUJARAT, DEVBHUMI DWARKA\n661732.986530\n4.002784e+09\nGUJARAT, DEVBHUMI DWARKA\nx24674\nMULTIPOLYGON (((7718827.698 2557929.563, 77188...\n4.242252e+09\n6.274325e+08\ntrain\n\n\n4\nGUJARAT\n24\nJAMNAGAR\n447\nGUJARAT, JAMNAGAR\n737428.071884\n5.694271e+09\nGUJARAT, JAMNAGAR\nx24447\nMULTIPOLYGON (((7852087.684 2560524.569, 78520...\n6.407889e+09\n5.365635e+08\ntrain\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n728\nASSAM\n18\nSONITPUR\n301\nASSAM, SONITPUR\n302021.098402\n3.318736e+09\nASSAM, SONITPUR\nx18301\nMULTIPOLYGON (((10326354.727 3126884.632, 1032...\n3.784846e+09\n0.000000e+00\ntrain\n\n\n729\nASSAM\n18\nSOUTH SALMARA MANCACHAR\n707\nASSAM, SOUTH SALMARA MANCACHAR\n234231.827116\n6.578689e+08\nASSAM, SOUTH SALMARA MANCACHAR\nx18707\nMULTIPOLYGON (((10026361.681 2997346.466, 1002...\n6.946624e+08\n0.000000e+00\ntrain\n\n\n730\nASSAM\n18\nTINSUKIA\n302\nASSAM, TINSUKIA\n419712.540770\n3.677172e+09\nASSAM, TINSUKIA\nx18302\nMULTIPOLYGON (((10683315.573 3243887.278, 1068...\n4.870746e+09\n0.000000e+00\ntrain\n\n\n731\nASSAM\n18\nUDALGURI\n617\nASSAM, UDALGURI\n363765.338478\n1.977228e+09\nASSAM, UDALGURI\nx18617\nMULTIPOLYGON (((10280044.090 3110745.402, 1028...\n2.535762e+09\n0.000000e+00\ntrain\n\n\n732\nASSAM\n18\nWEST KARBI ANGLONG\n710\nASSAM, WEST KARBI ANGLONG\n430785.104037\n2.957340e+09\nASSAM, WEST KARBI ANGLONG\nx18710\nMULTIPOLYGON (((10299580.450 3017866.006, 1029...\n3.810255e+09\n0.000000e+00\ntrain\n\n\n\n\n733 rows × 13 columns\n\n\n\n\n## add the train test information to the main_df\nmain_df['district_shapefile_code_x'] = main_df['district_shapefile_code_x'].astype(int)\ndist_with_splits['di_code'] = pd.to_numeric(dist_with_splits['di_code'], errors='coerce').astype('Int64')\nfinal_df = main_df.merge(dist_with_splits[['di_code', 'split']], \n                      left_on='district_shapefile_code_x', \n                      right_on='di_code', \n                      how='left').drop('di_code', axis=1)\n\n\nfinal_df.to_csv('250807_FinalCleanedData_PT.csv')",
    "crumbs": [
      "Data",
      "Spatial splitting for ML model"
    ]
  },
  {
    "objectID": "00_RAP_Framework_Overview.html#project-team",
    "href": "00_RAP_Framework_Overview.html#project-team",
    "title": "Flood and Drought Risk Analysis Perception (RAP) Framework for India",
    "section": "Project Team",
    "text": "Project Team\nTeam Leader\nJennifer Marlon, Ph.D.\nSchool of the Environment, Yale University, New Haven, CT, USA\nTeam Members (arranged in alphabetical order by last name)\nOkikiola Michael Alegbeleye\nSchool of the Environment, Washington State University, Pullman, WA, USA\nDeepika Pingali\nDepartment of Agricultural and Consumer Economics, University of Illinois Urbana–Champaign, Champaign, IL, USA\nEmine Senkardesler\nDepartment of Informatics (Spatial Informatics program), University of Illinois Urbana–Champaign, Champaign, IL, USA\nPratyush Tripathy\nDepartment of Geography, University of California, Santa Barbara, CA, USA\nSurabhi Upadhyay\nDepartment of Hydrologic Science and Engineering, Colorado School of Mines, Golden, CO, USA",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "00_RAP_Framework_Overview.html#context",
    "href": "00_RAP_Framework_Overview.html#context",
    "title": "Flood and Drought Risk Analysis Perception (RAP) Framework for India",
    "section": "Context",
    "text": "Context\nDeveloped for the I-GUIDE Summer School on Spatial AI for Extreme Events and Disaster Resilience (August 4–8, 2025), this notebook serves as the entry point to the RAP project documentation and provides links to the supporting analysis notebooks.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "00_RAP_Framework_Overview.html#overview",
    "href": "00_RAP_Framework_Overview.html#overview",
    "title": "Flood and Drought Risk Analysis Perception (RAP) Framework for India",
    "section": "Overview",
    "text": "Overview\nThe Risk Analysis Perception (RAP) Framework assesses perceptions of flood and drought risk across India using survey outcomes combined with geospatial and media features. The documentation consolidates methodology, datasets, modeling choices, and visualization outputs. The linked notebooks enable transparent navigation through data processing, model development, and results.\nObjectives - Quantify spatial variation in perceived flood and drought risk across Indian districts\n- Evaluate how individual demographics and district-level environmental and media signals relate to perception\n- Compare baseline and enhanced models that integrate remote sensing and learned embeddings\nStudy Area and Unit of Analysis - National coverage for India\n- Individual survey responses linked to district identifiers for spatial aggregation and modeling",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "00_RAP_Framework_Overview.html#data-and-variables",
    "href": "00_RAP_Framework_Overview.html#data-and-variables",
    "title": "Flood and Drought Risk Analysis Perception (RAP) Framework for India",
    "section": "Data and Variables",
    "text": "Data and Variables\n\nDependent Variable\n\nSurvey-based perception outcomes\n\nExample outcomes: perceived flood risk, perceived drought risk\n\nAggregated and modeled at individual level with district context\n\n\n\n\nCovariates\nIndividual-level - Age\n- Gender\n- Education\n- Caste\nDistrict-level - News media: web-scraped counts of flood-related mentions\n- Nighttime lights: VIIRS radiance as a proxy for human activity and development\n- Learned representations: Alpha Earth satellite embeddings to capture latent environmental and built-environment signals\n- Climate reanalysis (ERA5)\n- Monthly precipitation\n- Monthly temperature\nNotes to editors: finalize variable definitions, temporal windows, and any transformations or standardization applied before modeling.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "00_RAP_Framework_Overview.html#modeling-scenarios",
    "href": "00_RAP_Framework_Overview.html#modeling-scenarios",
    "title": "Flood and Drought Risk Analysis Perception (RAP) Framework for India",
    "section": "Modeling Scenarios",
    "text": "Modeling Scenarios\n\n\n\n\n\n\n\n\n\nModel\nDemographic Covariates(Age, Gender,Education, Caste)\nDistrict-Level Features(VIIRS Radiance, ERA5 Precipitation& Temperature, News Mentions)\nAlpha Earth Embeddings\n\n\n\n\n1\n✅\n❌\n❌\n\n\n2\n✅\n✅\n❌\n\n\n3\n✅\n❌\n✅\n\n\n4\n✅\n✅\n✅\n\n\n\nEvaluation: We perform a 5 fold cross-validation during model training and 80-20 train test split for after model training validation. The 80-20 split is done by randmly dividing the country in 250 km square grids and randomly selecting 20% of these 250 km grids to separate validation districts. We do this to account for autocorrelation that may exist in the model.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "00_RAP_Framework_Overview.html#workflow-and-linked-notebooks",
    "href": "00_RAP_Framework_Overview.html#workflow-and-linked-notebooks",
    "title": "Flood and Drought Risk Analysis Perception (RAP) Framework for India",
    "section": "Workflow and Linked Notebooks",
    "text": "Workflow and Linked Notebooks\n\nData Processing\n01_Data.ipynb\nSteps: data ingestion, cleaning, joins between survey and district features, feature engineering, QA checks\nModel Tuning and Training\n02_Model.ipynb\nSteps: scenario definitions, hyperparameter search, cross-validation strategy, diagnostics\nVisualization and Results\n03_Plots.ipynb\nSteps: maps and plots of outcomes and predictors, model comparison charts, error analysis",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "00_RAP_Framework_Overview.html#methods-summary",
    "href": "00_RAP_Framework_Overview.html#methods-summary",
    "title": "Flood and Drought Risk Analysis Perception (RAP) Framework for India",
    "section": "Methods Summary",
    "text": "Methods Summary\n\nPreprocessing: missing data handling, categorical encoding, scaling as needed\n\nSpatial linkage: survey responses associated with district codes; district-level covariates aligned by consistent spatial boundaries and time windows\n\nModeling: compare generalized linear or tree-based models with and without embeddings; record seeds and configs for reproducibility\n\nValidation: report effect sizes or feature importances with uncertainty; inspect residuals for spatial autocorrelation",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "00_RAP_Framework_Overview.html#reproducibility",
    "href": "00_RAP_Framework_Overview.html#reproducibility",
    "title": "Flood and Drought Risk Analysis Perception (RAP) Framework for India",
    "section": "Reproducibility",
    "text": "Reproducibility\n\nEnvironment file: environment.yml with pinned versions\n\nRandom seeds stored in notebook parameters or config files\n\nOutputs written to versioned folders: outputs/{date}/...\n\nOptional: parameterize runs with Papermill for batch execution",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "00_RAP_Framework_Overview.html#ethics-and-limitations",
    "href": "00_RAP_Framework_Overview.html#ethics-and-limitations",
    "title": "Flood and Drought Risk Analysis Perception (RAP) Framework for India",
    "section": "Ethics and Limitations",
    "text": "Ethics and Limitations\n\nSurvey privacy and de-identification\n\nPotential media bias and unequal reporting across districts\n\nSpatial and temporal mismatches between survey dates and covariate periods\n\nEmbeddings are powerful but may encode confounders; interpretability checks recommended",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "00_RAP_Framework_Overview.html#citation",
    "href": "00_RAP_Framework_Overview.html#citation",
    "title": "Flood and Drought Risk Analysis Perception (RAP) Framework for India",
    "section": "Citation",
    "text": "Citation\nIf you use or adapt this framework, please cite:\n&gt; Marlon, J., Alegbeleye, O. M., Pingali, D., Senkardesler, E., Tripathy, P., and Upadhyay, S. (2025). Flood and Drought Risk Analysis Perception (RAP) Framework for India.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "00_RAP_Framework_Overview.html#contact",
    "href": "00_RAP_Framework_Overview.html#contact",
    "title": "Flood and Drought Risk Analysis Perception (RAP) Framework for India",
    "section": "Contact",
    "text": "Contact\nFor questions about the project or data access, please contact the Team Leader or repository maintainer.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "03_Plots.html",
    "href": "03_Plots.html",
    "title": "Make the plots",
    "section": "",
    "text": "import pandas as pd\n\n# load model metrics from the drive\nmetrics1 = pd.read_csv('saved_models/model_metrics_model1.csv')\nmetrics2 = pd.read_csv('saved_models/model_metrics_model2.csv')\nmetrics3 = pd.read_csv('saved_models/model_metrics_model3.csv')\nmetrics4 = pd.read_csv('saved_models/model_metrics_model4.csv')\n\nprint('All metrics file loaded!')\n\n# load feature importance from the drive\nmodels = ['LogisticRegression', 'GradientBoosting', 'RandomForest']\nsuffixes = ['model1', 'model2', 'model3', 'model4']\n\nresults = {s: {m: pd.read_csv(f'saved_models/{m}_feature_importance_{s}.csv') \n              for m in models} for s in suffixes}\nimportance1 = results['model1']\nimportance2 = results['model2']\nimportance3 = results['model3']\nimportance4 = results['model4']\n\nprint('All feature importance files loaded!')\n\nAll metrics file loaded!\nAll feature importance files loaded!\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n\n# Set professional style\nplt.rcParams['font.family'] = 'DejaVu Sans'  # Changed from Arial\nplt.rcParams['font.size'] = 14  # Increased base font size\nplt.rcParams['axes.linewidth'] = 1.2\nplt.rcParams['grid.alpha'] = 0.3\nplt.rcParams['axes.spines.top'] = False     # Remove top spine\nplt.rcParams['axes.spines.right'] = False   # Remove right spine\nsns.set_palette(\"Set2\")\n\ndef plot_accuracy_metrics(metrics_list, model_suffixes, save_path=None):\n    \"\"\"\n    SLIDE 1: Model Performance Comparison\n    Professional accuracy metrics visualization\n    \"\"\"\n    \n    # Combine data\n    combined_data = []\n    for metrics_df, suffix in zip(metrics_list, model_suffixes):\n        temp_df = metrics_df.copy()\n        temp_df['Feature_Set'] = suffix\n        combined_data.append(temp_df)\n    \n    combined_df = pd.concat(combined_data, ignore_index=True)\n    \n    # Create figure with subplots\n    fig, axes = plt.subplots(2, 2, figsize=(18, 9))\n    \n    # Metrics to plot\n    metrics = [\n        ('Test_Accuracy', 'Accuracy', axes[0,0]),\n        ('Test_AUC', 'AUC-ROC', axes[0,1]),\n        ('Test_F1', 'F1-Score', axes[1,0]),\n        ('Test_Precision', 'Precision', axes[1,1])\n    ]\n    \n    for metric_col, metric_name, ax in metrics:\n        # Create bar plot\n        bars = sns.barplot(data=combined_df, x='Model', y=metric_col, hue='Feature_Set', ax=ax)\n        \n        # Customize appearance\n        ax.set_title(f'{metric_name}', fontsize=18, fontweight='bold', pad=20)\n        ax.set_xlabel('', fontsize=16, fontweight='bold')  # Removed 'Model Type'\n        ax.set_ylabel(metric_name, fontsize=16, fontweight='bold')\n        ax.grid(True, alpha=0.3, axis='y')\n        \n        # Increase tick label sizes\n        ax.tick_params(axis='both', which='major', labelsize=14)\n        \n        # Remove top and right spines\n        ax.spines['top'].set_visible(False)\n        ax.spines['right'].set_visible(False)\n        \n        # Add value labels on bars\n        for container in bars.containers:\n            bars.bar_label(container, fmt='%.2f', fontsize=12)\n        \n        # Set consistent y-axis limits for better comparison\n        y_min = max(0, combined_df[metric_col].min() - 0.05)\n        y_max = min(1, combined_df[metric_col].max() + 0.05)\n        ax.set_ylim(y_min, y_max)\n        \n        # Style legend - move to top right\n        if metric_name == 'Accuracy':  # Only show legend once\n            ax.legend(title='Feature Set', title_fontsize=14, fontsize=12, \n                     loc='upper right', frameon=True, fancybox=True, shadow=True)\n        else:\n            ax.get_legend().remove()\n    \n    plt.tight_layout()\n    \n    # Save with high DPI if path provided\n    if save_path:\n        plt.savefig(f'{save_path}_performance.png', dpi=300, bbox_inches='tight')\n    \n    plt.show()\n    \n    # Print summary table\n    print(\"\\n\" + \"=\"*80)\n    print(\"PERFORMANCE SUMMARY TABLE\")\n    print(\"=\"*80)\n    \n    summary_cols = ['Test_Accuracy', 'Test_AUC', 'Test_F1', 'Test_Precision']\n    for model in combined_df['Model'].unique():\n        print(f\"\\n{model}:\")\n        model_data = combined_df[combined_df['Model'] == model][['Feature_Set'] + summary_cols]\n        print(model_data.round(2).to_string(index=False))\n\ndef plot_feature_importance(feature_importance_dict, model_suffixes, save_path=None):\n    \"\"\"\n    SLIDE 2: Feature Importance Analysis\n    Professional feature importance visualization\n    \"\"\"\n    \n    models = ['LogisticRegression', 'GradientBoosting', 'RandomForest']\n    \n    for model in models:\n        fig, axes = plt.subplots(2, 2, figsize=(20, 12))\n        fig.suptitle(f'{model} Feature Importance', \n                     fontsize=24, fontweight='bold', y=0.95)\n        axes = axes.flatten()\n        \n        for i, suffix in enumerate(model_suffixes):\n            ax = axes[i]\n            \n            if suffix in feature_importance_dict and model in feature_importance_dict[suffix]:\n                importance_df = feature_importance_dict[suffix][model]\n                top_features = importance_df.head(12)  # Show top 12 for better visibility\n                \n                # Create horizontal bar plot\n                colors = plt.cm.viridis(np.linspace(0, 1, len(top_features)))\n                bars = ax.barh(range(len(top_features)), top_features['Importance'], \n                              color=colors, alpha=0.8, edgecolor='black', linewidth=0.5)\n                \n                # Customize appearance\n                ax.set_yticks(range(len(top_features)))\n                ax.set_yticklabels(top_features['Feature'], fontsize=13)\n                ax.set_xlabel('Feature Importance', fontsize=16)\n                ax.set_title(f'{suffix}', fontsize=18, fontweight='bold', pad=15)\n                ax.invert_yaxis()\n                ax.grid(True, alpha=0.3, axis='x')\n                \n                # Increase tick label sizes\n                ax.tick_params(axis='both', which='major', labelsize=14)\n                \n                # Remove top and right spines\n                ax.spines['top'].set_visible(False)\n                ax.spines['right'].set_visible(False)\n                \n                # Add value labels on bars\n                for j, bar in enumerate(bars):\n                    width = bar.get_width()\n                    ax.text(width + 0.01, bar.get_y() + bar.get_height()/2, \n                           f'{width:.2f}', ha='left', va='center', \n                           fontsize=12)\n                \n                # Removed ranking numbers as requested\n                \n            else:\n                ax.text(0.5, 0.5, f'No data available\\nfor {suffix}', \n                       transform=ax.transAxes, ha='center', va='center', \n                       fontsize=16, fontweight='bold', color='gray')\n                ax.set_title(f'{suffix}', fontsize=18)\n                # Remove spines for empty plots too\n                ax.spines['top'].set_visible(False)\n                ax.spines['right'].set_visible(False)\n        \n        plt.tight_layout()\n        plt.subplots_adjust(top=0.9)\n        \n        # Save with high DPI if path provided\n        if save_path:\n            plt.savefig(f'{save_path}_{model}_importance.png', dpi=300, bbox_inches='tight')\n        \n        plt.show()\n\n\n# Create plots\nmetrics_list = [metrics1, metrics2, metrics3, metrics4]\nmodel_suffixes = ['Model1', 'Model2', 'Model3', 'Model4']\nfeature_importance_dict = {\n    'Model1': importance1,\n    'Model2': importance2, \n    'Model3': importance3,\n    'Model4': importance4\n}\n\n# SLIDE 1: Performance Metrics (saves as 'plots_performance.png')\nplot_accuracy_metrics(metrics_list, model_suffixes, save_path='plots')\n\n# SLIDE 2: Feature Importance (saves as 'plots_RandomForest_importance.png', etc.)\nplot_feature_importance(feature_importance_dict, model_suffixes, save_path='plots')\n\n\n\n\n\n\n\n\n\n================================================================================\nPERFORMANCE SUMMARY TABLE\n================================================================================\n\nRandomForest:\nFeature_Set  Test_Accuracy  Test_AUC  Test_F1  Test_Precision\n     Model1           0.56      0.57     0.55            0.55\n     Model2           0.56      0.60     0.55            0.55\n     Model3           0.58      0.61     0.60            0.56\n     Model4           0.58      0.61     0.61            0.57\n\nGradientBoosting:\nFeature_Set  Test_Accuracy  Test_AUC  Test_F1  Test_Precision\n     Model1           0.56      0.59     0.51            0.56\n     Model2           0.57      0.61     0.53            0.58\n     Model3           0.57      0.61     0.58            0.56\n     Model4           0.58      0.61     0.59            0.57\n\nLogisticRegression:\nFeature_Set  Test_Accuracy  Test_AUC  Test_F1  Test_Precision\n     Model1           0.58      0.61     0.53            0.59\n     Model2           0.58      0.62     0.57            0.58\n     Model3           0.57      0.60     0.54            0.57\n     Model4           0.57      0.60     0.52            0.57",
    "crumbs": [
      "Results",
      "Make the plots"
    ]
  }
]